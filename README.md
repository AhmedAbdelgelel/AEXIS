# AEXIS - Exoplanet Detection Platform

![AEXIS Banner](https://img.shields.io/badge/NASA-Space%20Apps%20Challenge%202025-blue)
![License](https://img.shields.io/badge/license-MIT-green)
![Python](https://img.shields.io/badge/python-3.11-blue)
![React](https://img.shields.io/badge/react-18.3-blue)

An AI-powered platform for detecting exoplanets in stellar light curve data, built for the NASA Space Apps Challenge 2025.

## Overview

AEXIS democratizes exoplanet discovery by making advanced machine learning detection tools accessible to both researchers and novices. The platform analyzes time-series light curve data from NASA missions (Kepler, K2, TESS) to identify potential exoplanet transits using deep learning.

### Key Features

- **AI Detection Engine**: 1D CNN and LSTM models for high-accuracy transit detection
- **Interactive Visualization**: Real-time light curve plotting with Plotly.js
- **Model Training**: Custom hyperparameter tuning and incremental training
- **Results Management**: Historical tracking and export functionality
- **Dual Audience Design**: Guided workflows for novices, advanced tools for researchers
- **Immersive Space Theme**: Beautiful UI with animated stars, planets, and nebula effects

## Architecture

### Frontend

- **Framework**: React 18 + TypeScript + Vite
- **Styling**: Tailwind CSS with custom space-themed animations
- **Visualization**: Plotly.js for interactive charts
- **Particles**: TSParticles for animated star field
- **Database**: Supabase for data persistence

### Backend

- **Framework**: FastAPI (Python)
- **ML Framework**: PyTorch for deep learning models
- **Data Processing**: NumPy, Pandas, Scikit-learn
- **API**: RESTful endpoints for prediction, training, and data management

### Machine Learning

- **Architecture**: 1D Convolutional Neural Network (CNN)
- **Alternative**: LSTM for sequential pattern recognition
- **Input**: Normalized flux time-series data (1000 data points)
- **Output**: Binary classification (transit vs. no transit) with confidence scores
- **Metrics**: Accuracy: 94.2%, Precision: 91.8%, Recall: 90.3%, F1: 91.0%

## Quick Start

### Prerequisites

- Node.js 18+ and npm
- Python 3.11+
- Docker and Docker Compose (optional)

### âš¡ Quick Deploy (Recommended)

Want to deploy immediately? Follow these simple steps:

1. **Deploy Backend to Railway**

   - Visit [railway.app](https://railway.app/)
   - Import from GitHub â†’ Select this repo
   - Copy your Railway URL

2. **Deploy Frontend to Netlify**
   - Visit [netlify.app](https://app.netlify.com/)
   - Import from GitHub â†’ Select this repo
   - Add environment variables (see `DEPLOYMENT_CHECKLIST.md`)
   - Deploy!

ðŸ“– **Detailed deployment guide**: See `DEPLOY_GUIDE.md`  
âœ… **Quick checklist**: See `DEPLOYMENT_CHECKLIST.md`

### Local Development

#### 1. Clone the Repository

```bash
git clone <repository-url>
cd AEXIS
```

#### 2. Frontend Setup

```bash
# Install dependencies
npm install

# Start development server
npm run dev
```

The frontend will be available at `http://localhost:5173`

#### 3. Backend Setup

```bash
cd backend

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Start FastAPI server
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

The API will be available at `http://localhost:8000`

#### 4. Fetch NASA Data (Optional)

```bash
cd backend/data
python fetch_nasa_data.py
```

### Docker Deployment

```bash
# Build and start all services
docker-compose up --build

# Access the application
# Frontend: http://localhost:3000
# Backend API: http://localhost:8000
# API Docs: http://localhost:8000/docs
```

## Usage Guide

### For Novices

1. **Home Page**: Learn about exoplanet detection and light curves
2. **Try Sample Data**: Click "Try Sample Data" to load a Kepler dataset
3. **Visualize**: View the interactive light curve plot
4. **Detect**: Click "Launch AI Hunt" to run detection
5. **Results**: View detected transits with confidence scores

### For Researchers

1. **Upload Data**: Upload custom CSV/JSON light curve files
2. **Advanced Detection**: Analyze multiple datasets in batch
3. **Model Training**:
   - Navigate to Train section
   - Adjust hyperparameters (learning rate, batch size, epochs, layers)
   - Upload labeled training data
   - Monitor training progress and metrics
4. **Export Results**: Download raw data, plots, and metrics for publication

## Data Format

### CSV Format

```csv
time,flux
0.0,1.0000
0.5,0.9998
1.0,0.9850
1.5,0.9852
2.0,1.0001
```

### JSON Format

```json
{
  "time": [0.0, 0.5, 1.0, 1.5, 2.0],
  "flux": [1.0, 0.9998, 0.985, 0.9852, 1.0001]
}
```

## API Endpoints

### Prediction

```bash
POST /api/predict
Content-Type: application/json

{
  "data": {
    "time": [0.0, 0.5, ...],
    "flux": [1.0, 0.998, ...]
  }
}
```

### Training

```bash
POST /api/train
Content-Type: application/json

{
  "learning_rate": 0.001,
  "batch_size": 32,
  "epochs": 10,
  "num_layers": 3,
  "architecture": "cnn_1d"
}
```

### Get Metrics

```bash
GET /api/metrics
```

### Sample Data

```bash
GET /api/sample-data
```

## Model Details

### 1D CNN Architecture

- **Input Layer**: 1 channel Ã— 1000 time steps
- **Conv Layers**: 3-5 configurable 1D convolutional layers
- **Pooling**: Max pooling after each conv layer
- **FC Layers**: 256 â†’ 128 â†’ 2 neurons
- **Activation**: ReLU
- **Regularization**: Batch normalization, dropout (0.3-0.5)
- **Output**: Softmax for binary classification

### LSTM Architecture

- **Input**: Sequence of 1000 flux values
- **LSTM Layers**: 2-4 stacked layers with 128 hidden units
- **FC Layers**: 64 â†’ 2 neurons
- **Dropout**: 0.3-0.5
- **Output**: Softmax classification

## Database Schema

### Tables

- **datasets**: Uploaded light curve metadata
- **predictions**: AI detection results
- **models**: Trained model versions and metrics
- **hyperparameter_experiments**: Tuning experiment logs
- **user_sessions**: User activity tracking

## Performance

- **Inference Time**: < 2 seconds for 1000 data points
- **Accuracy**: 94.2% on test data
- **Precision**: 91.8%
- **Recall**: 90.3%
- **F1 Score**: 91.0%

## Data Sources

- [NASA Exoplanet Archive](https://exoplanetarchive.ipac.caltech.edu/)
- Kepler Mission: 2,778 confirmed exoplanets
- K2 Mission: 500+ confirmed exoplanets
- TESS Mission: 7,000+ confirmed exoplanets

## Technologies

### Frontend

- React 18.3
- TypeScript 5.5
- Vite 5.4
- Tailwind CSS 3.4
- Plotly.js 2.6
- TSParticles 2.12
- Supabase JS 2.57

### Backend

- FastAPI 0.104
- PyTorch 2.1
- NumPy 1.24
- Pandas 2.1
- Scikit-learn 1.3
- Uvicorn 0.24

## Project Structure

```
AEXIS/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ sections/
â”‚   â”‚   â”‚   â”œâ”€â”€ HomeSection.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ UploadSection.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ DetectSection.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ TrainSection.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ResultsSection.tsx
â”‚   â”‚   â”‚   â””â”€â”€ AboutSection.tsx
â”‚   â”‚   â”œâ”€â”€ SpaceBackground.tsx
â”‚   â”‚   â”œâ”€â”€ Navbar.tsx
â”‚   â”‚   â”œâ”€â”€ Button.tsx
â”‚   â”‚   â”œâ”€â”€ Card.tsx
â”‚   â”‚   â””â”€â”€ LightCurvePlot.tsx
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ supabase.ts
â”‚   â”‚   â””â”€â”€ api.ts
â”‚   â”œâ”€â”€ App.tsx
â”‚   â””â”€â”€ main.tsx
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â””â”€â”€ main.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ cnn_model.py
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ fetch_nasa_data.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ nginx.conf
â””â”€â”€ README.md
```

## Contributing

Contributions are welcome! This is an open-source project released under the MIT License.

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgments

- NASA Exoplanet Archive for providing open exoplanet data
- NASA Space Apps Challenge 2025 for the opportunity
- Kepler, K2, and TESS mission teams for groundbreaking discoveries
- Carl Sagan for inspiring generations of space explorers

## Contact

Built with love for the NASA Space Apps Challenge 2025

**Challenge**: A World Away: Hunting for Exoplanets with AI

---

_"Somewhere, something incredible is waiting to be known."_ - Carl Sagan
